# CodeHelperNET con Ollama

CodeHelperNET es un asistente especializado en C# y .NET que utiliza Ollama para generar respuestas inteligentes y especÃ­ficas.

## ğŸš€ CaracterÃ­sticas

- **Base de datos vectorial local** con informaciÃ³n especializada en C# y .NET
- **GeneraciÃ³n de respuestas con Ollama** (modelo local)
- **BÃºsqueda web** para informaciÃ³n actualizada
- **Respuestas especÃ­ficas** para preguntas sobre:
  - Sintaxis de C#
  - Ejemplos de cÃ³digo
  - Conceptos de .NET
  - Patrones de diseÃ±o
  - Conexiones a bases de datos
  - Y mucho mÃ¡s

## ğŸ“‹ Requisitos

- Python 3.8+
- Ollama instalado y ejecutÃ¡ndose
- Modelo Llama2 descargado

## ğŸ”§ InstalaciÃ³n

### 1. Instalar dependencias de Python

```bash
pip install -r requirements_complete.txt
```

### 2. Instalar Ollama

#### Linux/macOS:
```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

#### Windows:
Descarga desde: https://ollama.ai

### 3. Configurar Ollama automÃ¡ticamente

```bash
python setup_ollama.py
```

O manualmente:

```bash
# Iniciar Ollama
ollama serve

# En otra terminal, descargar el modelo
ollama pull llama2
```

## ğŸ¯ Uso

### Inicio rÃ¡pido

```bash
python start_chatbot.py
```

### Inicio manual

```bash
python rag_chatbot.py
```

## ğŸ’¬ Ejemplos de preguntas

El chatbot puede responder preguntas como:

- **"Â¿CÃ³mo crear un bucle for en C#?"**
- **"MuÃ©strame un ejemplo de hola mundo"**
- **"Â¿QuÃ© es Entity Framework?"**
- **"Â¿CÃ³mo conectar a una base de datos SQL Server?"**
- **"Explica el patrÃ³n Singleton"**
- **"Â¿Sintaxis de async/await en C#?"**
- **"Â¿CÃ³mo usar LINQ?"**
- **"Â¿QuÃ© son los delegates en C#?"**

## ğŸ”§ ConfiguraciÃ³n

### Cambiar modelo de Ollama

En `rag_chatbot.py`, lÃ­nea 385:

```python
self.model = "llama2"  # Cambiar a "mistral", "codellama", etc.
```

### Modelos recomendados

- **llama2**: Bueno para respuestas generales
- **mistral**: MÃ¡s rÃ¡pido y eficiente
- **codellama**: Especializado en cÃ³digo
- **llama2:13b**: Mejor calidad (mÃ¡s lento)

### Descargar otros modelos

```bash
ollama pull mistral
ollama pull codellama
ollama pull llama2:13b
```

## ğŸ› ï¸ SoluciÃ³n de problemas

### Ollama no responde

```bash
# Verificar si estÃ¡ ejecutÃ¡ndose
curl http://localhost:11434/api/tags

# Reiniciar Ollama
pkill ollama
ollama serve
```

### Error de modelo no encontrado

```bash
# Listar modelos disponibles
ollama list

# Descargar modelo especÃ­fico
ollama pull llama2
```

### Dependencias faltantes

```bash
# Reinstalar dependencias
pip install -r requirements_complete.txt
```

## ğŸ“ Estructura del proyecto

```
backend/
â”œâ”€â”€ rag_chatbot.py          # Chatbot principal
â”œâ”€â”€ setup_ollama.py         # ConfiguraciÃ³n automÃ¡tica
â”œâ”€â”€ start_chatbot.py        # Script de inicio
â”œâ”€â”€ requirements_complete.txt # Dependencias
â”œâ”€â”€ data/                   # Base de datos de conocimiento
â””â”€â”€ vector_db/             # Base de datos vectorial
```

## ğŸ”„ ActualizaciÃ³n

Para actualizar el sistema:

```bash
# Actualizar dependencias
pip install -r requirements_complete.txt --upgrade

# Actualizar Ollama
ollama pull llama2:latest
```

## ğŸ“ Soporte

Si tienes problemas:

1. Verifica que Ollama estÃ© ejecutÃ¡ndose
2. AsegÃºrate de tener el modelo descargado
3. Revisa los logs de error
4. Ejecuta `python setup_ollama.py` para diagnÃ³stico

## ğŸ‰ Â¡Listo!

Ahora tienes un asistente inteligente especializado en C# y .NET que puede:

- Responder preguntas especÃ­ficas sobre sintaxis
- Generar ejemplos de cÃ³digo
- Explicar conceptos de .NET
- Ayudar con patrones de diseÃ±o
- Proporcionar informaciÃ³n sobre bases de datos

Â¡Disfruta programando con C# y .NET! ğŸš€ 