#!/usr/bin/env python3
"""
Script para configurar Ollama autom√°ticamente
"""

import subprocess
import sys
import requests
import time
import os

def check_ollama_installed():
    """Verificar si Ollama est√° instalado"""
    try:
        result = subprocess.run(['ollama', '--version'], capture_output=True, text=True)
        return result.returncode == 0
    except FileNotFoundError:
        return False

def install_ollama():
    """Instalar Ollama"""
    print("üîß Instalando Ollama...")
    
    # Detectar el sistema operativo
    import platform
    system = platform.system().lower()
    
    if system == "linux":
        # Instalar en Linux
        try:
            subprocess.run([
                "curl", "-fsSL", "https://ollama.ai/install.sh", "|", "sh"
            ], shell=True, check=True)
            print("‚úÖ Ollama instalado en Linux")
            return True
        except subprocess.CalledProcessError:
            print("‚ùå Error instalando Ollama en Linux")
            return False
    
    elif system == "darwin":  # macOS
        try:
            subprocess.run([
                "curl", "-fsSL", "https://ollama.ai/install.sh", "|", "sh"
            ], shell=True, check=True)
            print("‚úÖ Ollama instalado en macOS")
            return True
        except subprocess.CalledProcessError:
            print("‚ùå Error instalando Ollama en macOS")
            return False
    
    elif system == "windows":
        print("‚ö†Ô∏è  Para Windows, instala Ollama manualmente desde: https://ollama.ai")
        return False
    
    else:
        print(f"‚ö†Ô∏è  Sistema operativo no soportado: {system}")
        return False

def check_ollama_running():
    """Verificar si Ollama est√° ejecut√°ndose"""
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=5)
        return response.status_code == 200
    except:
        return False

def start_ollama():
    """Iniciar Ollama"""
    print("üöÄ Iniciando Ollama...")
    
    try:
        # Iniciar Ollama en segundo plano
        subprocess.Popen(['ollama', 'serve'], 
                        stdout=subprocess.DEVNULL, 
                        stderr=subprocess.DEVNULL)
        
        # Esperar a que inicie
        for i in range(30):  # Esperar hasta 30 segundos
            if check_ollama_running():
                print("‚úÖ Ollama iniciado correctamente")
                return True
            time.sleep(1)
        
        print("‚ùå Ollama no pudo iniciarse")
        return False
        
    except Exception as e:
        print(f"‚ùå Error iniciando Ollama: {e}")
        return False

def download_model(model_name="llama2"):
    """Descargar modelo de Ollama"""
    print(f"üì• Descargando modelo {model_name}...")
    
    try:
        subprocess.run(['ollama', 'pull', model_name], check=True)
        print(f"‚úÖ Modelo {model_name} descargado correctamente")
        return True
    except subprocess.CalledProcessError:
        print(f"‚ùå Error descargando modelo {model_name}")
        return False

def test_ollama():
    """Probar Ollama"""
    print("üß™ Probando Ollama...")
    
    try:
        response = requests.post(
            "http://localhost:11434/api/generate",
            json={
                "model": "llama2",
                "prompt": "Hola, ¬øc√≥mo est√°s?",
                "stream": False
            },
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            if result.get("response"):
                print("‚úÖ Ollama funciona correctamente")
                return True
        
        print("‚ùå Ollama no responde correctamente")
        return False
        
    except Exception as e:
        print(f"‚ùå Error probando Ollama: {e}")
        return False

def main():
    """Funci√≥n principal"""
    print("ü§ñ Configurando Ollama para CodeHelperNET")
    print("=" * 50)
    
    # Verificar si Ollama est√° instalado
    if not check_ollama_installed():
        print("üì¶ Ollama no est√° instalado")
        if not install_ollama():
            print("\nüí° Instalaci√≥n manual:")
            print("1. Ve a https://ollama.ai")
            print("2. Descarga e instala Ollama para tu sistema")
            print("3. Ejecuta este script nuevamente")
            return False
    
    print("‚úÖ Ollama est√° instalado")
    
    # Verificar si Ollama est√° ejecut√°ndose
    if not check_ollama_running():
        print("üîÑ Ollama no est√° ejecut√°ndose")
        if not start_ollama():
            print("\nüí° Para iniciar Ollama manualmente:")
            print("1. Abre una terminal")
            print("2. Ejecuta: ollama serve")
            print("3. En otra terminal, ejecuta: ollama run llama2")
            return False
    
    print("‚úÖ Ollama est√° ejecut√°ndose")
    
    # Descargar modelo si es necesario
    try:
        subprocess.run(['ollama', 'list'], check=True, capture_output=True)
    except subprocess.CalledProcessError:
        if not download_model():
            print("\nüí° Para descargar el modelo manualmente:")
            print("ollama pull llama2")
            return False
    
    # Probar Ollama
    if test_ollama():
        print("\nüéâ ¬°Ollama est√° configurado correctamente!")
        print("\nüí° Ahora puedes ejecutar CodeHelperNET:")
        print("python rag_chatbot.py")
        return True
    else:
        print("\n‚ùå Ollama no est√° funcionando correctamente")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 